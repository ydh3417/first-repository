{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-07-08T06:05:15.896261Z","iopub.execute_input":"2022-07-08T06:05:15.896655Z","iopub.status.idle":"2022-07-08T06:05:15.906311Z","shell.execute_reply.started":"2022-07-08T06:05:15.896624Z","shell.execute_reply":"2022-07-08T06:05:15.904890Z"},"trusted":true},"execution_count":325,"outputs":[]},{"cell_type":"code","source":"import numpy as np # 행렬이나 일반적으로 대규모 다차원 배열을 쉽게 처리할 수 있도록 지원하는 파이썬의 라이브러리이다.\nimport pandas as pd # 파이썬 데이터 처리를 위한 라이브러리, 특히 숫자테이블과 시계열을 조작하기 위한 데이터 구조와 연산을 제공.\nimport matplotlib.pyplot as plt # 파이썬 및 숫자 확장 넘파이를 활용한 플로팅 라이브러리, 객체 지향 API를 제공, MATLAB에 대한 실행 가능한 오픈소스 대안을 제공.\nimport seaborn as sns # Matplotlib을 기반으로 다양한 색상 테마와 통계용 차트 등의 기능을 추가한 시각화 패키지이다. 기본적인 시각화 기능은 Matplotlib 패키지에 의존하며 통계기능은 Statsmodels 패키지에 의존한다.\n# seaborn 과 matplotlib은 시각화 단계\nplt.style.use('seaborn')\nsns.set(font_scale=2.5) # 이 두줄은 본 필자가 항상 쓰는 방법 입니다. matplotlib 의 기본 scheme 말고 seaborn scheme 을 세팅하고, 일일이 graph 의 font size를 지정할 필요 없이 seaborn의 font_scale 을 사용하면 편합니다.\n# scheme란 스킴이라고 하며 스키마와 혼동할수 있으나 스키마는 대략적인 계획이나 도식을 뜻하는 데 비해 스킴은 구체적이고 확정된 것을 말한다.\nimport missingno as msno\n\n#ignore warnings\nimport warnings\nwarnings.filterwarnings('ignore')\n\n%matplotlib inline","metadata":{"execution":{"iopub.status.busy":"2022-07-08T06:05:15.909048Z","iopub.execute_input":"2022-07-08T06:05:15.909513Z","iopub.status.idle":"2022-07-08T06:05:15.922830Z","shell.execute_reply.started":"2022-07-08T06:05:15.909473Z","shell.execute_reply":"2022-07-08T06:05:15.921571Z"},"trusted":true},"execution_count":326,"outputs":[]},{"cell_type":"markdown","source":"* 앞으로 우리가 해야할 프로세스는 대략 아래와 같습니다\n  1. 데이터셋 확인 - 대부분의 캐글 테이터들은 잘 정제되어 있습니다. 하지만 가끔 null data가 존재합니다. 이를 확인하고, 향후 수정합니다.\n  2. 탐색적 데이터 분석(exploratory data analysis) - 여러 feature 들을 개별적으로 분석하고, feature 들 간의 상관관계를 확인합니      다.\n  3. feature engineering - 모델을 세우기에 앞서, 모델의 성능을 높일 수 잇도록 feature 들을 engineering 합니다.\n     one-hot encoding, class로 나누기, 구간으로 나누기, 텍스트 데이터 처리 등을 합니다.\n  4. model 만들기 - sklearn 을 사용해 모델을 만듭니다. 파이썬에서 머신러닝을 할 때는 sklearn을 사용하면 수많은 알고리즘을 일관된 문법으      로 사용할수 있습니다. 물론 딥러닝을 위해 tensorflow, pytorch 등을 사용할 수 도 있습니다. (sklearn -> scikit-learn으로 python을 대표하는 머신러닝 라이브러리. 머신러닝 모델에 대해 설명","metadata":{}},{"cell_type":"markdown","source":"# 1. Dataset 확인\n  - 파이썬에서 테이블화 된 데이터를 다루는 데 가장 최적화되어 있으며, 많이 쓰는 라이브러리는 pandas 입니다.\n  - 우리는 pandas 를 사용하여 데이터셋의 간단한 통계적 분석부터, 복잡한 처리들을 간단한 메소드를 통해 사용하여 해낼 수 있습니다.\n  - 파이썬으로 데이터 분석을 한다고 하면 반드시 능훅해져야 할 라이브러리이니, 여러 커널들을 반복 또 반복하시길 권장합니다.\n  - 캐글에서 데이터셋은 보통 train, testset 으로 나뉘어 있습니다","metadata":{}},{"cell_type":"code","source":"df_train = pd.read_csv('../input/titanic/train.csv')\ndf_test = pd.read_csv('../input/titanic/test.csv')","metadata":{"execution":{"iopub.status.busy":"2022-07-08T06:05:15.924822Z","iopub.execute_input":"2022-07-08T06:05:15.925229Z","iopub.status.idle":"2022-07-08T06:05:15.949550Z","shell.execute_reply.started":"2022-07-08T06:05:15.925190Z","shell.execute_reply":"2022-07-08T06:05:15.948740Z"},"trusted":true},"execution_count":327,"outputs":[]},{"cell_type":"code","source":"df_train.head()","metadata":{"execution":{"iopub.status.busy":"2022-07-08T06:05:15.951210Z","iopub.execute_input":"2022-07-08T06:05:15.951886Z","iopub.status.idle":"2022-07-08T06:05:15.968064Z","shell.execute_reply.started":"2022-07-08T06:05:15.951854Z","shell.execute_reply":"2022-07-08T06:05:15.967029Z"},"trusted":true},"execution_count":328,"outputs":[]},{"cell_type":"markdown","source":"* 우리가 다루는 문제에서 feature는 pclass, age, SibSp, Parch, Fare 이며, 예측하려는 target label 은 Survived 입니다.","metadata":{}},{"cell_type":"code","source":"df_train.describe()","metadata":{"execution":{"iopub.status.busy":"2022-07-08T06:05:15.969958Z","iopub.execute_input":"2022-07-08T06:05:15.970429Z","iopub.status.idle":"2022-07-08T06:05:16.000636Z","shell.execute_reply.started":"2022-07-08T06:05:15.970400Z","shell.execute_reply":"2022-07-08T06:05:15.999522Z"},"trusted":true},"execution_count":329,"outputs":[]},{"cell_type":"code","source":"df_test.describe()","metadata":{"execution":{"iopub.status.busy":"2022-07-08T06:05:16.002389Z","iopub.execute_input":"2022-07-08T06:05:16.002703Z","iopub.status.idle":"2022-07-08T06:05:16.034440Z","shell.execute_reply.started":"2022-07-08T06:05:16.002673Z","shell.execute_reply":"2022-07-08T06:05:16.033185Z"},"trusted":true},"execution_count":330,"outputs":[]},{"cell_type":"markdown","source":"* 테이블에서 보다시피, PassenserID 숫자와 다른, 그러니깐 null data가 존재하는 열(feature)가 있는 것 같습니다. \n* 이를 좀더 보기 편하기 그래프로 시각화해서 살펴봅시다","metadata":{}},{"cell_type":"markdown","source":"* train 과 test로 분리하는 이유 \n데이터를 분석한다는 것은 보통 데이터가 주어지면 모델링을 통해 특정 규칙을 찾아 output을 예측하는 것이 목표. 가장 적절한 모델을 찾기 위해 데이터를 train data 와 test data 로 나눈 뒤 train data에 각각의 모델로 학습시켜 test data로 각 모델의 최종 정확도를 확인하기위해서 분리함\n* 그렇다면 왜 굳이 train 과 test로 나누는건가?\n우리가 궁극적으로 할 것은 unseen data를 예측 혹은 분류하는 것인데 unseen data는 말 그대로 아직 일어나지 않은일의 데이터로 존재하지 않음\n그래서 현재 가지고 있는 data를 trainrhk test 로 나눠서 train으로만 학습하면서 최적의 매개변수를 찾고, 그런 다음 Test를 사용하여 모델의 실력을 평가하는 것입니다. (ex. 정확도, MSE...)","metadata":{}},{"cell_type":"markdown","source":"# 1.1 Null data check\n","metadata":{}},{"cell_type":"code","source":"for col in df_train.columns: #.columns 는 데이터프레임 열의 이름을 조회하기 위한 용도로 쓰여졌다.\n    msg = 'column: {:>10}\\t Percent of NaN value: {:.2f}%'.format(col, 100 * (df_train[col].isnull().sum( ) / df_train[col].shape[0]))\n    print(msg)\n    # .format 은 포메팅 함수. 문자열을 이쁘게 만드는 용도 구조 '{인덱스0},{인덱스1}'.format(값0,값1)\n    # isnull 결측치 행 확인 메소드. 각 원소의 NaN 값 여부가 표시","metadata":{"execution":{"iopub.status.busy":"2022-07-08T06:05:16.036146Z","iopub.execute_input":"2022-07-08T06:05:16.036465Z","iopub.status.idle":"2022-07-08T06:05:16.047604Z","shell.execute_reply.started":"2022-07-08T06:05:16.036436Z","shell.execute_reply":"2022-07-08T06:05:16.046403Z"},"trusted":true},"execution_count":331,"outputs":[]},{"cell_type":"code","source":"for col in df_test.columns:\n    msg = 'column {:>10}\\t Percent of NaN value: {:2f}%'.format(col, 100 * (df_test[col].isnull().sum() / df_test[col].shape[0]))\n    print(msg)","metadata":{"execution":{"iopub.status.busy":"2022-07-08T06:05:16.049587Z","iopub.execute_input":"2022-07-08T06:05:16.050417Z","iopub.status.idle":"2022-07-08T06:05:16.065865Z","shell.execute_reply.started":"2022-07-08T06:05:16.050371Z","shell.execute_reply":"2022-07-08T06:05:16.064993Z"},"trusted":true},"execution_count":332,"outputs":[]},{"cell_type":"markdown","source":"* Train, Test set 에서 Age(둘다 약 20%), Cabin(둘다 약 80%), Embarked(Train만 0.22%) null data 존재하는 것을 볼 수 있습니다.\n* MANO 라는 라이브러리를 사용하면 null data의 존재를 더 쉽게 볼 수 있습니다.","metadata":{}},{"cell_type":"code","source":"msno.matrix(df=df_train.iloc[:, :], figsize=(8, 8), color=(0.8, 0.5, 0.2)) # 여기서도 msno.matrix 가 뭐고 어떤 역할인지 찾기 ","metadata":{"execution":{"iopub.status.busy":"2022-07-08T06:05:16.070027Z","iopub.execute_input":"2022-07-08T06:05:16.070637Z","iopub.status.idle":"2022-07-08T06:05:16.430185Z","shell.execute_reply.started":"2022-07-08T06:05:16.070592Z","shell.execute_reply":"2022-07-08T06:05:16.428316Z"},"trusted":true},"execution_count":333,"outputs":[]},{"cell_type":"code","source":"msno.bar(df=df_train.iloc[:, :], figsize=(8, 8), color=(0.8, 0.5, 0.2)) # 여기 msno.bar 이게 뭔지 찾기","metadata":{"execution":{"iopub.status.busy":"2022-07-08T06:05:16.431989Z","iopub.execute_input":"2022-07-08T06:05:16.432280Z","iopub.status.idle":"2022-07-08T06:05:17.213350Z","shell.execute_reply.started":"2022-07-08T06:05:16.432254Z","shell.execute_reply":"2022-07-08T06:05:17.212037Z"},"trusted":true},"execution_count":334,"outputs":[]},{"cell_type":"code","source":"msno.bar(df=df_test.iloc[:, :], figsize=(8, 8), color=(0.8, 0.5, 0.2))","metadata":{"execution":{"iopub.status.busy":"2022-07-08T06:05:17.215011Z","iopub.execute_input":"2022-07-08T06:05:17.216190Z","iopub.status.idle":"2022-07-08T06:05:17.948852Z","shell.execute_reply.started":"2022-07-08T06:05:17.216124Z","shell.execute_reply":"2022-07-08T06:05:17.947582Z"},"trusted":true},"execution_count":335,"outputs":[]},{"cell_type":"markdown","source":"# 1.2 Target label 확인\n* target label 이 어떤 distribution 을 가지고 있는지 지금 확인해봐야 합니다.\n* 지금 같은 binary classification 문제의 경우에서, 1과 0의 분포가 어떠냐에 따라 모델의 평가 방법이 달라 질 수 있습니다.","metadata":{}},{"cell_type":"code","source":"f, ax = plt.subplots(1, 2, figsize=(18, 8))\n\ndf_train['Survived'].value_counts().plot.pie(explode=[0, 0.1], autopct='%1.1f%%', ax=ax[0], shadow=True) # pi위에 표시될 글자 형태, 또한 알아서 %로 변환해서 알려줌\nax[0].set_title('Pie plot - Survived')\nax[0].set_ylabel('')\nsns.countplot('Survived', data=df_train, ax=ax[1])\nax[1].set_title('Count plot - Survived')\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-07-08T06:05:17.950497Z","iopub.execute_input":"2022-07-08T06:05:17.951696Z","iopub.status.idle":"2022-07-08T06:05:18.245578Z","shell.execute_reply.started":"2022-07-08T06:05:17.951637Z","shell.execute_reply":"2022-07-08T06:05:18.244572Z"},"trusted":true},"execution_count":336,"outputs":[]},{"cell_type":"markdown","source":"* 안타깝게도 죽은 사람이 많습니다\n* 38.4 % 가 살아남았습니다.\n* target label 의 분포가 제법 균일(balanced)합니다. 불균일한 경우, 예를 들어서 100중 1이 99, 0이 1개인 경우에는 만약 모델이 모든 것을 1이라 해도 정확도가 99%가 나오게 됩니다. 0을 찾는 문제라면 이 모델은 원하는 결과를 줄 수 없게 됩니다. 지금 문제에서는 그렇지 않으니 계속 진행하겠습니다.","metadata":{}},{"cell_type":"markdown","source":"# 2. Exploratory data analysis\n* 이제 본격적으로 데이터분석을 해보겠습니다. 데이터는 매우 많습니다. 이 많은 데이터 안에 숨겨진 사실을 찾기 위해선 적절한 시각화가 필요합니다.\n* 시각화 라이브러리는 matplotlib, seaborn, plotly 등이 있습니다. 특정 목적에 맞는 소스코드를 정리해두어 필요할때마다 참고하면 편합니다.\n## 2.1 pclass\n* 먼저 Pclass에 대해서 살펴보겠습니다. Pclass는 ordinal, 서수형 데이터입니다. 카테고리이면서, 순서가 있는 데이터 타입입니다.\n* 먼저 Pclass에 따른 생존률 차이를 살펴보겠습니다. 엑셀의 피벗 차트와 유사한 작업을 하게 되는데, pandas dataframe에서는 groupby를 사용하면 쉽게 할 수 있습니다. 또한 pivot 이라는 메소드도 있습니다.\n*  'Pclass', 'Survived'를 가져온 후, pclass 로 묶습니다. 그러고 나면 각 pclass 마다 0,1 이 count가 되는데,이를 평균내면 각 pclass 별 생존률이 나옵니다.\n* 아래와 같이 count()를 하면, 각 class에 몇명이 있는지 확인할 수 잇으며, sum() 을 하면, 216명중 생존한 (survived=1)사람의 총합을 주게 됩니다.","metadata":{}},{"cell_type":"code","source":"df_train[['Pclass', 'Survived']].groupby(['Pclass'],as_index=True).count() #groupby()는 연산자로 그룹별로 데이터를 집계, 요약하는 용도. groupby를 쓰면 기본적으로 그룹라벨이 index가 되는데 index를 사용하고 싶지 않을 떄는 as_indes=False를 설정하면 됨","metadata":{"execution":{"iopub.status.busy":"2022-07-08T06:05:18.246669Z","iopub.execute_input":"2022-07-08T06:05:18.247798Z","iopub.status.idle":"2022-07-08T06:05:18.261282Z","shell.execute_reply.started":"2022-07-08T06:05:18.247749Z","shell.execute_reply":"2022-07-08T06:05:18.260098Z"},"trusted":true},"execution_count":337,"outputs":[]},{"cell_type":"code","source":"df_train[['Pclass', 'Survived']].groupby(['Pclass'],as_index=True).sum()","metadata":{"execution":{"iopub.status.busy":"2022-07-08T06:05:18.262873Z","iopub.execute_input":"2022-07-08T06:05:18.263238Z","iopub.status.idle":"2022-07-08T06:05:18.279673Z","shell.execute_reply.started":"2022-07-08T06:05:18.263165Z","shell.execute_reply":"2022-07-08T06:05:18.278813Z"},"trusted":true},"execution_count":338,"outputs":[]},{"cell_type":"markdown","source":"* pandas의 crosstab을 사용하면 좀 더 위 과정을 좀 더 수월하게 볼 수 있습니다.","metadata":{}},{"cell_type":"code","source":"pd.crosstab(df_train['Pclass'], df_train['Survived'],margins=True).style.background_gradient(cmap='summer_r') #crosstab은 pivot table의 일종으로 두 column의 교차 빈도, 비율, 덧셈 등을 구할때 주로 사용 \n# cmap은 map에 색깔을 나오게 함","metadata":{"execution":{"iopub.status.busy":"2022-07-08T06:05:18.280811Z","iopub.execute_input":"2022-07-08T06:05:18.281289Z","iopub.status.idle":"2022-07-08T06:05:18.330189Z","shell.execute_reply.started":"2022-07-08T06:05:18.281257Z","shell.execute_reply":"2022-07-08T06:05:18.329406Z"},"trusted":true},"execution_count":339,"outputs":[]},{"cell_type":"markdown","source":"* grouped 객체에 mean()을 하게 되면, 각 클래스별 생존률을 얻을 수 있습니다. class 1 이면 아래와 같습니다.$80\\over(80+136)$ $\\approx 0.63$","metadata":{}},{"cell_type":"code","source":"df_train[['Pclass', 'Survived']].groupby(['Pclass'], as_index=True).mean().sort_values(by='Survived', ascending=False).plot.bar()","metadata":{"execution":{"iopub.status.busy":"2022-07-08T06:05:18.331556Z","iopub.execute_input":"2022-07-08T06:05:18.332050Z","iopub.status.idle":"2022-07-08T06:05:18.469907Z","shell.execute_reply.started":"2022-07-08T06:05:18.332007Z","shell.execute_reply":"2022-07-08T06:05:18.468774Z"},"trusted":true},"execution_count":340,"outputs":[]},{"cell_type":"markdown","source":"* 보다시피, Pclass 가 좋을 수록(1st) 생존률이 높은 것을 확인할 수 있습니다.\n* 좀 더 보기 쉽게 그래프를 그려보겠습니다. seaborn의 countplot을 이용하면, 특정 label에 따른 개수를 확인해볼 수 있습니다.","metadata":{}},{"cell_type":"code","source":"y_position = 1.02\nf, ax = plt.subplots(1, 2, figsize=(18, 8))\ndf_train['Pclass'].value_counts().plot.bar(color=['#CD7F32','#FFDF00','#D3D3D3'], ax=ax[0])\nax[0].set_ylabel('Count')\nsns.countplot('Pclass', hue='Survived', data=df_train, ax=ax[1])\nax[1].set_title('Pclass : Survived vs Dead', y=y_position)","metadata":{"execution":{"iopub.status.busy":"2022-07-08T06:05:18.472037Z","iopub.execute_input":"2022-07-08T06:05:18.473236Z","iopub.status.idle":"2022-07-08T06:05:18.795017Z","shell.execute_reply.started":"2022-07-08T06:05:18.473177Z","shell.execute_reply":"2022-07-08T06:05:18.793938Z"},"trusted":true},"execution_count":341,"outputs":[]},{"cell_type":"markdown","source":"* '''클래스가 높을 수록, 생존확률이 높은걸 확인할 수 있습니다. Pclass 1, 2, 3 순서대로 63%, 48%, 25% 입니다.'''\n* 우리는 생존에 Pclass가 큰 영향을 미친다고 생각해볼 수 있으며, 나중에 모델을 세울 때 이 feature 를 사용해보는 것이 좋을 것이라 판단할 수 있습니다.","metadata":{}},{"cell_type":"markdown","source":"# Sex\n*     이번에는 성별로 생존률이 어떻게 달라지는 지 확인해보겠습니다.\n*    마찬가지로 pandas groupby 와 seaborn countplot 을 사용해서 시각화해봅시다.","metadata":{}},{"cell_type":"code","source":"f, ax = plt.subplots(1, 2, figsize=(18, 8))\ndf_train[['Sex','Survived']].groupby(['Sex'], as_index=True).mean().plot.bar(ax=ax[0])\nax[0].set_title('Survived vs Sex')\nsns.countplot('Sex', hue='Survived', data=df_train, ax=ax[1])\nax[1].set_title('Sex: survived vs Dead')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-07-08T06:05:18.796229Z","iopub.execute_input":"2022-07-08T06:05:18.796510Z","iopub.status.idle":"2022-07-08T06:05:19.129645Z","shell.execute_reply.started":"2022-07-08T06:05:18.796484Z","shell.execute_reply":"2022-07-08T06:05:19.128621Z"},"trusted":true},"execution_count":342,"outputs":[]},{"cell_type":"markdown","source":"* 보시다시피, 여자가 생존할 확률이 높습니다.","metadata":{}},{"cell_type":"code","source":"df_train[['Sex', 'Survived']].groupby(['Sex'], as_index=False).mean().sort_values(by='Survived', ascending=False)","metadata":{"execution":{"iopub.status.busy":"2022-07-08T06:05:19.130926Z","iopub.execute_input":"2022-07-08T06:05:19.131501Z","iopub.status.idle":"2022-07-08T06:05:19.149098Z","shell.execute_reply.started":"2022-07-08T06:05:19.131458Z","shell.execute_reply":"2022-07-08T06:05:19.147865Z"},"trusted":true},"execution_count":343,"outputs":[]},{"cell_type":"code","source":"pd.crosstab(df_train['Sex'], df_train['Survived'], margins=True).style.background_gradient(cmap='summer_r')","metadata":{"execution":{"iopub.status.busy":"2022-07-08T06:05:19.150706Z","iopub.execute_input":"2022-07-08T06:05:19.151190Z","iopub.status.idle":"2022-07-08T06:05:19.197435Z","shell.execute_reply.started":"2022-07-08T06:05:19.151153Z","shell.execute_reply":"2022-07-08T06:05:19.196332Z"},"trusted":true},"execution_count":344,"outputs":[]},{"cell_type":"markdown","source":"* Pclass와 마찬가지로, Sex도 예측 모델에 쓰일 중요한 feature임을 알 수 있습니다","metadata":{}},{"cell_type":"markdown","source":"# 2.3 Both Sex and Pclass\n*   이번에는 Sex, Pclass 두가지에 관하여 생존이 어떻게 달라지는 지 확인해 봅시다\n*   seaborn 의 factorplot을 이용하면, 손쉽게 3개의 차원으로 이루어진 그래프를 그릴 수 있습니다.","metadata":{}},{"cell_type":"code","source":"sns.factorplot('Pclass', 'Survived', hue='Sex', data=df_train,                            size=6, aspect=1.5) # 여기에는 왜 코드를 중간에 띄워둔걸까","metadata":{"execution":{"iopub.status.busy":"2022-07-08T06:05:19.198835Z","iopub.execute_input":"2022-07-08T06:05:19.199220Z","iopub.status.idle":"2022-07-08T06:05:19.788386Z","shell.execute_reply.started":"2022-07-08T06:05:19.199177Z","shell.execute_reply":"2022-07-08T06:05:19.786963Z"},"trusted":true},"execution_count":345,"outputs":[]},{"cell_type":"markdown","source":"*     모든 클래스에서 female 이 살 확률이 male 보다 높은 걸 알 수 있습니다.\n*     또한 남자, 여자 상관없이 클래스가 높을 수록 살 확률이 높습니다.\n*     위 그래프는 hue 대신 column으로 하면 아래와 같아집니다.","metadata":{}},{"cell_type":"code","source":"sns.factorplot(x='Sex', y='Survived', col='Pclass', data=df_train, satureation=5, size = 9, axpect = 1)","metadata":{"execution":{"iopub.status.busy":"2022-07-08T06:05:19.789796Z","iopub.execute_input":"2022-07-08T06:05:19.790143Z","iopub.status.idle":"2022-07-08T06:05:20.585332Z","shell.execute_reply.started":"2022-07-08T06:05:19.790113Z","shell.execute_reply":"2022-07-08T06:05:20.584196Z"},"trusted":true},"execution_count":346,"outputs":[]},{"cell_type":"markdown","source":"# 2.4 Age\n*    이번에는 Age feature를 살펴봅시다.","metadata":{}},{"cell_type":"code","source":"print('제일 나이 많은 탑승객 : {:.1f}) Years'.format(df_train['Age'].max()))\nprint('제일 어린 탑승객 : {:.1f} Years'.format(df_train['Age'].min()))\nprint('탑승객 평균 나이 : {:.1f} Years'.format(df_train['Age'].mean()))","metadata":{"execution":{"iopub.status.busy":"2022-07-08T06:05:20.591535Z","iopub.execute_input":"2022-07-08T06:05:20.591898Z","iopub.status.idle":"2022-07-08T06:05:20.600595Z","shell.execute_reply.started":"2022-07-08T06:05:20.591869Z","shell.execute_reply":"2022-07-08T06:05:20.599137Z"},"trusted":true},"execution_count":347,"outputs":[]},{"cell_type":"markdown","source":"* 생존에 따른 Age의 histogram을 그려보겠습니다.","metadata":{}},{"cell_type":"code","source":"fig, ax = plt.subplots(1, 1, figsize=(9, 5)) #fig는 figure로써 전체 subplot을 말한다-> 전체사이즈 ax는 axe로써 - 전체 중 낱낱개를 말한다. \nsns.kdeplot(df_train[df_train['Survived'] == 1]['Age'], ax=ax)\nsns.kdeplot(df_train[df_train['Survived'] == 0]['Age'], ax=ax)\nplt.legend(['Survived == 1', 'Survived == 0'])\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-07-08T06:05:20.602048Z","iopub.execute_input":"2022-07-08T06:05:20.602990Z","iopub.status.idle":"2022-07-08T06:05:20.869751Z","shell.execute_reply.started":"2022-07-08T06:05:20.602954Z","shell.execute_reply":"2022-07-08T06:05:20.868616Z"},"trusted":true},"execution_count":348,"outputs":[]},{"cell_type":"markdown","source":"* 보시다시피, 생존자 중 나이가 어린 경우가 많음을 볼 수 있습니다.","metadata":{}},{"cell_type":"code","source":"# Age distribution withing classes\nplt.figure(figsize=(8, 6)) # figsize는 그래프의 사이즈를 설정하는 용도\ndf_train['Age'][df_train['Pclass']==1].plot(kind='kde')\ndf_train['Age'][df_train['Pclass']==2].plot(kind='kde')\ndf_train['Age'][df_train['Pclass']==3].plot(kind='kde')\n\nplt.xlabel('Age')\nplt.title('Age Distribution within classes')\nplt.legend(['1st Class','2nd Class', '3rd Class'])","metadata":{"execution":{"iopub.status.busy":"2022-07-08T06:05:20.871267Z","iopub.execute_input":"2022-07-08T06:05:20.871611Z","iopub.status.idle":"2022-07-08T06:05:21.156244Z","shell.execute_reply.started":"2022-07-08T06:05:20.871579Z","shell.execute_reply":"2022-07-08T06:05:21.155429Z"},"trusted":true},"execution_count":349,"outputs":[]},{"cell_type":"markdown","source":"* class 가 높을수록 나이 많은 사람의 비중이 커짐\n* 나이대가 변하면서 생존률이 어떻게 되는지 보려고 합니다.\n* 나이범위를 점점 넓혀가며, 생존률이 어떻게 되는지 한번 봅시다.","metadata":{}},{"cell_type":"code","source":"cummulate_survival_ratio = []\nfor i in range(1, 80):\n    cummulate_survival_ratio.append(df_train[df_train['Age']<i]['Survived'].sum() / len(df_train[df_train['Age']<i]['Survived']))\n\nplt.figure(figsize=(7, 7))\nplt.plot(cummulate_survival_ratio)\nplt.title('Survival rate change depending on range of Age', y=1.02)\nplt.ylabel('Survival rate')\nplt.xlabel('Range of Age(0~x)')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-07-08T06:05:21.157583Z","iopub.execute_input":"2022-07-08T06:05:21.158429Z","iopub.status.idle":"2022-07-08T06:05:21.424908Z","shell.execute_reply.started":"2022-07-08T06:05:21.158390Z","shell.execute_reply":"2022-07-08T06:05:21.423836Z"},"trusted":true},"execution_count":350,"outputs":[]},{"cell_type":"markdown","source":"* 보시다시피, 나이가 어릴 수록 생존률이 확실히 높은 것을 확인할 수 있습니다.\n* 우리는 이 나이가 중요한 feature로 쓰일 수 있음을 확인했습니다.","metadata":{}},{"cell_type":"markdown","source":"# 2.5 Pclass, Sex, Age\n*  지금까지 본, Sex, Pclass, Age, Survived 모두에 대해서 보고싶습니다. 이를 쉽게 그려주는 것이 seaborn의 violinplot 입니다.\n*  x축은 우리가 나눠서 보고싶어하는 case(여기선 Pclass, distribution(Age) 입니다.\n*  한번 그려보겠습니다.","metadata":{}},{"cell_type":"code","source":"f, ax=plt.subplots(1,2,figsize=(18, 8))\nsns.violinplot(\"Pclass\",\"Age\", hue=\"Survived\", data=df_train, scale='count', split=True,ax=ax[0])\nax[0].set_title('Pclass and Age vs Survived')\nax[0].set_yticks(range(0,110,10))\nsns.violinplot(\"Sex\",\"Age\",hue=\"Survived\", data=df_train, scale='count', split=True, ax=ax[1])\nax[1].set_title('Sex and Age vs Survived')\nax[1].set_yticks(range(0,110,10))\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-07-08T06:05:21.426644Z","iopub.execute_input":"2022-07-08T06:05:21.427092Z","iopub.status.idle":"2022-07-08T06:05:21.906758Z","shell.execute_reply.started":"2022-07-08T06:05:21.427052Z","shell.execute_reply":"2022-07-08T06:05:21.905997Z"},"trusted":true},"execution_count":351,"outputs":[]},{"cell_type":"markdown","source":"* 왼쪽 그림은 Pclass 별로 Age의 distribution 이 어떻게 다른지, 거기에 생존여부에 따라 구분한 그래프 입니다.\n* 오른쪽 그림도 마찬가지 Sex, 생존에 따른 distribution이 어떻게 다른지 보여주는 그래프 입니다.\n* 생존만 봤을 때, 모든 클래스에서 나이가 어릴수록 생존을 많이 한 것을 볼 수 있습니다.\n* 오른쪽 그림에서 보면, 명확히 여자가 생존을 많이 한 것을 볼 수 있습니다.\n* 여성과 아이를 먼저 챙긴 것을 볼 수 있습니다.","metadata":{}},{"cell_type":"markdown","source":"# 2.6 Embarked\n*  Embarked는 탑승한 항구를 나타냅니다.\n*  위에서 해왔던 것과 비슷하게 탑승한 곳에 따른 생존률을 보겠습니다.","metadata":{}},{"cell_type":"code","source":"f, ax = plt.subplots(1, 1, figsize=(7, 7))\ndf_train[['Embarked', 'Survived']].groupby(['Embarked'], as_index=True).mean().sort_values(by='Survived',ascending=False).plot.bar(ax=ax)","metadata":{"execution":{"iopub.status.busy":"2022-07-08T06:05:21.907746Z","iopub.execute_input":"2022-07-08T06:05:21.908659Z","iopub.status.idle":"2022-07-08T06:05:22.103985Z","shell.execute_reply.started":"2022-07-08T06:05:21.908625Z","shell.execute_reply":"2022-07-08T06:05:22.103039Z"},"trusted":true},"execution_count":352,"outputs":[]},{"cell_type":"markdown","source":"* 보시다시피, 조금의 차이는 있지만 생존률은 좀 비슷한 거 같습니다. 그래도 C가 제일 높군요.\n* 모델에 얼마나 큰 영향을 미칠지는 모르겠지만, 그래도 사용하겠습니다.\n* 사실, 모델을 만들고 나면 우리가 사용한 feature 들이 얼마나 중요한 역할을 했는지 확인해볼 수 있습니다. 이는 추후에 모델을 만들고 난 다음에 살펴볼 것입니다\n* 다른 feature로 split하여 한번 살펴보겠습니다.","metadata":{}},{"cell_type":"code","source":"f,ax=plt.subplots(2,2,figsize=(20, 15))\nsns.countplot('Embarked', data=df_train, ax=ax[0,0])\nax[0,0].set_title('(1)No. Of Passengers Boarded')\nsns.countplot('Embarked',hue='Sex',data=df_train, ax=ax[0,1])\nax[0,1].set_title('(2) Male-Female Split for Embarked')\nsns.countplot('Embarked', hue='Survived',data=df_train, ax=ax[1,0])\nax[1,0].set_title('(3) Embarked vs Survived')\nsns.countplot('Embarked', hue='Pclass', data=df_train, ax=ax[1,1])\nax[1,1].set_title('(4) Embarked vs Pclass')\nplt.subplots_adjust(wspace=0.2, hspace=0.5)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-07-08T06:05:22.105192Z","iopub.execute_input":"2022-07-08T06:05:22.105503Z","iopub.status.idle":"2022-07-08T06:05:22.699618Z","shell.execute_reply.started":"2022-07-08T06:05:22.105473Z","shell.execute_reply":"2022-07-08T06:05:22.698582Z"},"trusted":true},"execution_count":353,"outputs":[]},{"cell_type":"markdown","source":"* Figure(1) - 전체적으로 봤을 때, S에서 가장 많은 사람이 탑승했습니다.\n* Figure(2) - C와 Q는 남녀의 비율이 비슷하고, S는 남자가 더 많습니다.\n* Figure(3) - 생존확률이 S 경우 많이 낮은 걸 볼 수 있습니다.\n* Fiugre(4) - Class로 split해서 보니, c가 생존확률이 높은건 클래스가 높은 사람이 많이 타서 그렇습니다. s 는 3rd class가 많아서 생존확률이 낮게 나옵니다.","metadata":{}},{"cell_type":"markdown","source":"# 2.7 Family - Sibsp(형제 자매) + Parch(부모, 자녀)\n*  SibSp와 Parch를 합하면 Family가 될 것입니다.\n*  Family 로 합쳐서 분석해봅시다.","metadata":{}},{"cell_type":"code","source":"df_train['FamilySize'] = df_train['SibSp'] + df_train['Parch'] + 1 # 자신을 포함해야하니 1을 더합니다.\ndf_test['FamilySize'] = df_test['SibSp'] + df_test['Parch'] + 1 # 자신을 포함해야하니 1을 더합니다.","metadata":{"execution":{"iopub.status.busy":"2022-07-08T06:05:22.701472Z","iopub.execute_input":"2022-07-08T06:05:22.701781Z","iopub.status.idle":"2022-07-08T06:05:22.709212Z","shell.execute_reply.started":"2022-07-08T06:05:22.701753Z","shell.execute_reply":"2022-07-08T06:05:22.707978Z"},"trusted":true},"execution_count":354,"outputs":[]},{"cell_type":"code","source":"print(\"Maximum size of Family: \", df_train['FamilySize'].max())\nprint(\"Minimum size of Family: \", df_train['FamilySize'].min())","metadata":{"execution":{"iopub.status.busy":"2022-07-08T06:05:22.710474Z","iopub.execute_input":"2022-07-08T06:05:22.710930Z","iopub.status.idle":"2022-07-08T06:05:22.722349Z","shell.execute_reply.started":"2022-07-08T06:05:22.710899Z","shell.execute_reply":"2022-07-08T06:05:22.721134Z"},"trusted":true},"execution_count":355,"outputs":[]},{"cell_type":"markdown","source":"* FamilySize 와 생존의 관계를 한번 살펴봅시다.","metadata":{}},{"cell_type":"code","source":"f,ax = plt.subplots(1, 3, figsize=(40,10))\nsns.countplot('FamilySize', data=df_train, ax=ax[0])\nax[0].set_title('(1) No. Of Passengers Boarded', y=1.02)\n\nsns.countplot('FamilySize', hue='Survived', data=df_train, ax=ax[1])\nax[1].set_title('(2) Survived countplot depending on FamilySize',  y=1.02)\n\ndf_train[['FamilySize', 'Survived']].groupby(['FamilySize'], as_index=True).mean().sort_values(by='Survived', ascending=False).plot.bar(ax=ax[2])\nax[2].set_title('(3) Survived rate depending on FamilySize',  y=1.02)\n\nplt.subplots_adjust(wspace=0.2, hspace=0.5)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-07-08T06:05:22.723738Z","iopub.execute_input":"2022-07-08T06:05:22.724046Z","iopub.status.idle":"2022-07-08T06:05:23.317819Z","shell.execute_reply.started":"2022-07-08T06:05:22.724018Z","shell.execute_reply":"2022-07-08T06:05:23.316529Z"},"trusted":true},"execution_count":356,"outputs":[]},{"cell_type":"markdown","source":"* Figure (1) - 가족크기가 1~11까지 있음을 볼 수 있습니다. 대부분 1명이고 그 다음으로 2, 3, 4명입니다.\n* Figure (2), (3) - 가족 크기에 따른 생존비교입니다. 가족이 4명인 경우가 가장 생존확률이 높습니다. 가족수가 많아질수록, (5, 6, 7, 8, 11) 생존확률이 낮아지네요. 가족수가 너무 작아도(1), 너무 커도(5, 6, 8, 11) 생존 확률이 작네요. 3~4명 선에서 생존확률이 높은 걸 확인할 수 있습니다.\n","metadata":{}},{"cell_type":"markdown","source":"# 2.8 Fare\n*  Fare는  탑승요금이며, contious feature 입니다. 한번 historgram을 그려보겠습니다.","metadata":{}},{"cell_type":"code","source":"fig, ax = plt.subplots(1, 1, figsize=(8, 8))\ng = sns.distplot(df_train['Fare'], color='b', label='Skewness : {:.2f}'.format(df_train['Fare'].skew()), ax=ax)\ng = g.legend(loc='best')","metadata":{"execution":{"iopub.status.busy":"2022-07-08T06:05:23.319671Z","iopub.execute_input":"2022-07-08T06:05:23.320074Z","iopub.status.idle":"2022-07-08T06:05:23.638286Z","shell.execute_reply.started":"2022-07-08T06:05:23.320034Z","shell.execute_reply":"2022-07-08T06:05:23.637040Z"},"trusted":true},"execution_count":357,"outputs":[]},{"cell_type":"markdown","source":"* 보시다시피, distribution이 매우 비대칭인 것을 알 수 있습니다.(high skewness). 만약 이대로 모델에 넣어준다면 자칫 모델이 잘못 학습할 수도 있습니다. 몇개 없는 outlier에 대해서 너무 민감하게 반응한다면, 실제 예측 시에 좋지 못한 결과를 부를 수 있습니다.\n* outlier의 영향을 줄이기 위해 Fare에 log를 취하겠습니다. \n* 여기서 우리는 pandas의 유용한 기능을 사용할 겁니다. dataFrame의 특정 columns에 공통된 작업(함수)를 적용하고 싶으면 아래의 map, 도는 apply를 사용하면 매우 쉽게 적용할 수 있습니다.\n* 우리가 지금 원하는 것은 Fare columns 의 데이터 모두를 log값 취하는 것인데, 파이썬의 간단한 lambda 함수를 이용해 간단한 로그를 적용하는 map에 인수로 넣어주면, Fare columns 데이터에 그대로 적용이 됩니다. 매우 유용한 기능이니 꼭 숙지하세요!","metadata":{}},{"cell_type":"code","source":"# 아래 줄은 뒤늦게 발견하였습니다. 13번쨰 강의에 언급되니, 일단 따라치시고 넘어가면 됩니다.\ndf_test.loc[df_test.Fare.isnull(),'Fare']=df_test['Fare'].mean() # testset 에 있는 nan value를 평균값으로 치환합니다.\n\ndf_train['Fare'] = df_train['Fare'].map(lambda i: np.log(i) if i > 0 else 0)\ndf_test['Fare'] = df_test['Fare'].map(lambda i: np.log(i) if i > 0 else 0)","metadata":{"execution":{"iopub.status.busy":"2022-07-08T06:05:23.639798Z","iopub.execute_input":"2022-07-08T06:05:23.640113Z","iopub.status.idle":"2022-07-08T06:05:23.650379Z","shell.execute_reply.started":"2022-07-08T06:05:23.640077Z","shell.execute_reply":"2022-07-08T06:05:23.649088Z"},"trusted":true},"execution_count":358,"outputs":[]},{"cell_type":"code","source":"fig, ax = plt.subplots(1, 1, figsize=(8, 8))\ng = sns.distplot(df_train['Fare'],color='b', label='Skewness : {:.2f}'.format(df_train['Fare'].skew()), ax=ax) # distplot은 distribuiton plot이라고 생각하면 될거 같다. 분포그래프.\ng = g.legend(loc='best')","metadata":{"execution":{"iopub.status.busy":"2022-07-08T06:05:23.652048Z","iopub.execute_input":"2022-07-08T06:05:23.652349Z","iopub.status.idle":"2022-07-08T06:05:23.956490Z","shell.execute_reply.started":"2022-07-08T06:05:23.652322Z","shell.execute_reply":"2022-07-08T06:05:23.955010Z"},"trusted":true},"execution_count":359,"outputs":[]},{"cell_type":"markdown","source":"* log를 취하니, 이제 비대칭성이 많이 사리진 것을 볼 수 있습니다.\n* 우리는 이런 작업을 사용해 모델이 좀 더 좋은 성능을 내도록 할 수 있습니다.\n* 사실 방금한 것은 feature engineering 에 들어가는 부분인데, 여기서 작업했습니다.\n* 모델을 학습시키기 위해, 그리고 그 모델의 성능을 높이기 위해 feature 들에 여러조작을 가하거나, 새로운 feature를 추가하는 것을 feature engineering이라고 하는데, 우리는 이제 그것을 살펴볼 것입니다.","metadata":{}},{"cell_type":"markdown","source":"# 2.9 Cabin\n*   이 features는 NaN이 대략 80%이므로, 생존에 영향을 미칠 중요한 정보를 얻어내기가 쉽지는 않습니다.\n*   그러므로 우리가 세우려는 모델에 포함시키지 않도록 하겠습니다.","metadata":{}},{"cell_type":"code","source":"df_train.head()","metadata":{"execution":{"iopub.status.busy":"2022-07-08T06:05:23.957866Z","iopub.execute_input":"2022-07-08T06:05:23.958268Z","iopub.status.idle":"2022-07-08T06:05:23.973595Z","shell.execute_reply.started":"2022-07-08T06:05:23.958236Z","shell.execute_reply":"2022-07-08T06:05:23.972520Z"},"trusted":true},"execution_count":360,"outputs":[]},{"cell_type":"markdown","source":"# 2.10 Ticket\n*    이 feature는 NaN은 없습니다. 일단 string data이므로 우리가 어떤 작업들을 해주어야 실제 모델에 사용할 수 있는데, 이를 위해선 사실 아이디어가 필요합니다.","metadata":{}},{"cell_type":"code","source":"df_train['Ticket'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2022-07-08T06:05:23.974936Z","iopub.execute_input":"2022-07-08T06:05:23.975248Z","iopub.status.idle":"2022-07-08T06:05:23.989230Z","shell.execute_reply.started":"2022-07-08T06:05:23.975221Z","shell.execute_reply":"2022-07-08T06:05:23.987905Z"},"trusted":true},"execution_count":361,"outputs":[]},{"cell_type":"markdown","source":"* 보시다시피, ticket number는 매우 다양합니다. 우리는 여기서 어떤 특징을 이끌어내서 생존과 연관시킬 수 있을까요?\n","metadata":{}},{"cell_type":"markdown","source":"# 3. Feature engineering\n*    본격적인 feature engineering을 시작해보겠습니다.\n*    가장먼저, dataset 에 존재하는 null data를 채우려고 합니다\n*    아무 숫자로 채울 수는 없고, null data를 포한하는 feature의 statistics 를 참고하거나, 다른 아이디어를 짜내어 채울 수 있습니다.\n*    null data 를 어떻게 채우느냐에 따라 모델의 성능이 좌지우지될수 있기 때문에, 신경써줘야할 부분입니다.\n*    Feature engineering은 실제 모델의 학습에 쓰려고 하는 것이므로, train 뿐만 아니라 test도 똑같이 적용해줘야 합니다. 잊지맙시다","metadata":{}},{"cell_type":"markdown","source":"## 3.1 Fill Null\n### 3.1.1 Fill Null in Age using title\n* Age에는 null data가 177개나 있습니다. 이를 채울 수 있는 여러 아이디어가 있을 것인데, 여기서 우리는 title + statistics를 사용해 보겠습니다.\n* 영어에는 Miss, Mrs 같은 title이 존재합니다. 각 탑승갱의 이름에는 꼭 이런 title이 들어가게 되는데 이를 사용해보겠습니다.\n* pandas series 에는 data를 string으로 바꿔주는 str method, 거기에 정규표현식을 적용하게 해주는 extract method가 있습니다. 이를 사용하여 title을 쉽게 추출할 수 있습니다. title을 Initial column에 저장하겠습니다.","metadata":{}},{"cell_type":"code","source":"df_train['Initial']=df_train.Name.str.extract('([A-Za-z]+)\\.') # lets extract the Salutations\n\ndf_test['Initial']=df_test.Name.str.extract('([A-Za-z]+)\\.') # lets extract the Salutations","metadata":{"execution":{"iopub.status.busy":"2022-07-08T06:05:23.991861Z","iopub.execute_input":"2022-07-08T06:05:23.992268Z","iopub.status.idle":"2022-07-08T06:05:24.325115Z","shell.execute_reply.started":"2022-07-08T06:05:23.992235Z","shell.execute_reply":"2022-07-08T06:05:24.323933Z"},"trusted":true},"execution_count":362,"outputs":[]},{"cell_type":"markdown","source":"* pandas 의 crosstab을 이용하여 우리가 추출한 Initial과 Sex간의 count를 살펴봅시다.","metadata":{}},{"cell_type":"code","source":"pd.crosstab(df_train['Initial'], df_train['Sex']).T.style.background_gradient(cmap='summer_r') #Checking the Initials with the Sex","metadata":{"execution":{"iopub.status.busy":"2022-07-08T06:05:24.326586Z","iopub.execute_input":"2022-07-08T06:05:24.326926Z","iopub.status.idle":"2022-07-08T06:05:24.373322Z","shell.execute_reply.started":"2022-07-08T06:05:24.326896Z","shell.execute_reply":"2022-07-08T06:05:24.372381Z"},"trusted":true},"execution_count":363,"outputs":[]},{"cell_type":"markdown","source":"* 위 table을 참고하여, 남자, 여자가 쓰는 initial을 구분해 보겠습니다. replace 메소드를 사용하면, 특정 데이터 값을 원하는 값으로 치환해줍니다.","metadata":{}},{"cell_type":"code","source":"df_train['Initial'].replace(['Mlle','Mme','Ms','Dr','Major','Lady','Countess','Jonkheer','Col','Rev','Capt','Sir','Don', 'Dona'],\n                        ['Miss','Miss','Miss','Mr','Mr','Mrs','Mrs','Other','Other','Other','Mr','Mr','Mr', 'Mr'],inplace=True)\n\ndf_test['Initial'].replace(['Mlle','Mme','Ms','Dr','Major','Lady','Countess','Jonkheer','Col','Rev','Capt','Sir','Don', 'Dona'],\n                        ['Miss','Miss','Miss','Mr','Mr','Mrs','Mrs','Other','Other','Other','Mr','Mr','Mr', 'Mr'],inplace=True)","metadata":{"execution":{"iopub.status.busy":"2022-07-08T06:05:24.374630Z","iopub.execute_input":"2022-07-08T06:05:24.374953Z","iopub.status.idle":"2022-07-08T06:05:24.386182Z","shell.execute_reply.started":"2022-07-08T06:05:24.374924Z","shell.execute_reply":"2022-07-08T06:05:24.385156Z"},"trusted":true},"execution_count":364,"outputs":[]},{"cell_type":"code","source":"df_train.groupby('Initial').mean()","metadata":{"execution":{"iopub.status.busy":"2022-07-08T06:05:24.387473Z","iopub.execute_input":"2022-07-08T06:05:24.388119Z","iopub.status.idle":"2022-07-08T06:05:24.407752Z","shell.execute_reply.started":"2022-07-08T06:05:24.388083Z","shell.execute_reply":"2022-07-08T06:05:24.406805Z"},"trusted":true},"execution_count":365,"outputs":[]},{"cell_type":"markdown","source":"* 여성과 관계있는 Miss, Mr, Mrs 가 생존률이 높은 것을 볼 수 있습니다.","metadata":{}},{"cell_type":"code","source":"df_train.groupby('Initial')['Survived'].mean().plot.bar()","metadata":{"execution":{"iopub.status.busy":"2022-07-08T06:05:24.408804Z","iopub.execute_input":"2022-07-08T06:05:24.409376Z","iopub.status.idle":"2022-07-08T06:05:24.588587Z","shell.execute_reply.started":"2022-07-08T06:05:24.409343Z","shell.execute_reply":"2022-07-08T06:05:24.587584Z"},"trusted":true},"execution_count":366,"outputs":[]},{"cell_type":"markdown","source":"* 이제 본격적으로 Null 을 채울 것입니다. null data를 채우는 방법은 정말 많이 존재합니다. statistics 를 활용하는 방법도 있고, null data가 없는 데이터를 기반으로 새로운 머신러닝 알고리즘을 만들어 예측해서 채워넣는 방식도 있습니다. 여기서는 statistics를 활용하는 방법을 사용할 것입니다.\n* 여기서 statistics 는 train data의 것을 의미합니다. 우리는 언제나 test를 unseen으로 둔 상태로 놔둬야 하며, train에서 얻은 statisics를 기반으로 testdml null data를 채워줘야 합니다.","metadata":{}},{"cell_type":"code","source":"df_train.groupby('Initial').mean()","metadata":{"execution":{"iopub.status.busy":"2022-07-08T06:05:24.589975Z","iopub.execute_input":"2022-07-08T06:05:24.590484Z","iopub.status.idle":"2022-07-08T06:05:24.607623Z","shell.execute_reply.started":"2022-07-08T06:05:24.590454Z","shell.execute_reply":"2022-07-08T06:05:24.606852Z"},"trusted":true},"execution_count":367,"outputs":[]},{"cell_type":"markdown","source":"* Age의 평균을 이용해 Null value를 채우도록 하겠습니다.\n* pandas dataframe 을 다룰 때에는 booltean array를 이용해 indexing 하는 방법이 참으로 편리합니다.\n* 아래 코드 첫줄을 해석하면, isnull() 이면서 Initial이 Mr인 조건을 만족하는 row(탑승객)의 'Age'의 값을 33으로 치환한다 입니다.\n* loc + boolean + column 을 사용해 값을 치환하는 방법은 자주 쓰이므로 꼭 익숙해집시다.\n","metadata":{}},{"cell_type":"code","source":"df_train.loc[(df_train.Age.isnull())&(df_train.Initial=='Mr'),'Age'] = 33\ndf_train.loc[(df_train.Age.isnull())&(df_train.Initial=='Mrs'),'Age'] = 36\ndf_train.loc[(df_train.Age.isnull())&(df_train.Initial=='Master'),'Age'] = 5\ndf_train.loc[(df_train.Age.isnull())&(df_train.Initial=='Miss'),'Age'] = 22\ndf_train.loc[(df_train.Age.isnull())&(df_train.Initial=='Other'),'Age'] = 46\n\ndf_test.loc[(df_test.Age.isnull())&(df_test.Initial=='Mr'),'Age'] = 33\ndf_test.loc[(df_test.Age.isnull())&(df_test.Initial=='Mrs'),'Age'] = 36\ndf_test.loc[(df_test.Age.isnull())&(df_test.Initial=='Master'),'Age'] = 5\ndf_test.loc[(df_test.Age.isnull())&(df_test.Initial=='Miss'),'Age'] = 22\ndf_test.loc[(df_test.Age.isnull())&(df_test.Initial=='Other'),'Age'] = 46","metadata":{"execution":{"iopub.status.busy":"2022-07-08T06:05:24.608886Z","iopub.execute_input":"2022-07-08T06:05:24.609358Z","iopub.status.idle":"2022-07-08T06:05:24.628155Z","shell.execute_reply.started":"2022-07-08T06:05:24.609326Z","shell.execute_reply":"2022-07-08T06:05:24.627156Z"},"trusted":true},"execution_count":368,"outputs":[]},{"cell_type":"markdown","source":"* 여기선 간단하게 Null을 채웠지만, 좀 더 다양한 방법을 쓴 예시들이 다른 커널에 존재합니다.","metadata":{}},{"cell_type":"markdown","source":"## 3.1.2 Fill Null in Embarked","metadata":{}},{"cell_type":"code","source":"print('Embarked has ', sum(df_train['Embarked'].isnull()), 'Null values')","metadata":{"execution":{"iopub.status.busy":"2022-07-08T06:05:24.629401Z","iopub.execute_input":"2022-07-08T06:05:24.629700Z","iopub.status.idle":"2022-07-08T06:05:24.644580Z","shell.execute_reply.started":"2022-07-08T06:05:24.629672Z","shell.execute_reply":"2022-07-08T06:05:24.643618Z"},"trusted":true},"execution_count":369,"outputs":[]},{"cell_type":"markdown","source":"* Embarked 는 Null value가 2개이고, S에서 가장 많은 탑승객이 있었으므로, 간단하게 Null을 S로 채우겠습니다.\n* dataframe 의 fillna method를 이용하면 쉽게 채울 수 있습니다. 여기서 inplace=True 로 하면 df_train 에 fillna를 실제로 적용하게 됩니다.","metadata":{}},{"cell_type":"code","source":"df_train['Embarked'].fillna('S', inplace=True)","metadata":{"execution":{"iopub.status.busy":"2022-07-08T06:05:24.646106Z","iopub.execute_input":"2022-07-08T06:05:24.646419Z","iopub.status.idle":"2022-07-08T06:05:24.656469Z","shell.execute_reply.started":"2022-07-08T06:05:24.646391Z","shell.execute_reply":"2022-07-08T06:05:24.655638Z"},"trusted":true},"execution_count":370,"outputs":[]},{"cell_type":"markdown","source":"## 3.2 Change Age(continuous to categorical)\n*    Age는 현재 continuous feature입니다. 이대로 써도 모델을 세울 수 있지만, Age를 몇개 group으로 나누어 category화 시켜줄 수 도 있습니다. continuous를 categorical로 바꾸면 자칫 information loss가 생길 수도 있습니다만, 본 튜토리얼에서는 다양한 방법틀 소개하는 것이 목적이므로 진행하도록 하겠습니다.\n*    방법은 여러가지가 있습니다. ataframe의 Indexing방법인 loc를 사용하여 직접해줄 수 있고, 아니면 apply를 사용해 함수를 넣어줄 수 있습니다.\n*    첫번째로 loc를 사용한 방법입니다. loc는 자주쓰게 되므로 그 사용법을 숙지하면 좋습니다.\n*    나이는 10살 간격으로 나누겠습니다.","metadata":{}},{"cell_type":"code","source":"df_train['Age_cat'] = 0\ndf_train.loc[df_train['Age']<10,'Age_cat']=0\ndf_train.loc[(10<=df_train['Age']) & (df_train['Age']<20), 'Age_cat'] =1\ndf_train.loc[(20<=df_train['Age']) & (df_train['Age']<30), 'Age_cat'] =2\ndf_train.loc[(30<=df_train['Age']) & (df_train['Age']<40), 'Age_cat'] =3\ndf_train.loc[(40<=df_train['Age']) & (df_train['Age']<50), 'Age_cat'] =4\ndf_train.loc[(50<=df_train['Age']) & (df_train['Age']<60), 'Age_cat'] =5\ndf_train.loc[(60<=df_train['Age']) & (df_train['Age']<27), 'Age_cat'] =6\ndf_train.loc[70<=df_train['Age'], 'Age_cat'] = 7\n\ndf_test['Age_cat'] = 0\ndf_test.loc[df_test['Age']<10, 'Age_cat'] = 0\ndf_test.loc[(10<=df_test['Age']) & (df_test['Age'] < 20), 'Age_cat'] = 1\ndf_test.loc[(20<=df_test['Age']) & (df_test['Age'] < 30), 'Age_cat'] = 2\ndf_test.loc[(30<=df_test['Age']) & (df_test['Age'] < 40), 'Age_cat'] = 3\ndf_test.loc[(40<=df_test['Age']) & (df_test['Age'] < 50), 'Age_cat'] = 4\ndf_test.loc[(50<=df_test['Age']) & (df_test['Age'] < 60), 'Age_cat'] = 5\ndf_test.loc[(60<=df_test['Age']) & (df_test['Age'] < 27), 'Age_cat'] = 6\ndf_test.loc[70 <= df_test['Age'], 'Age_cat'] = 7","metadata":{"execution":{"iopub.status.busy":"2022-07-08T06:05:24.657616Z","iopub.execute_input":"2022-07-08T06:05:24.658665Z","iopub.status.idle":"2022-07-08T06:05:24.685696Z","shell.execute_reply.started":"2022-07-08T06:05:24.658583Z","shell.execute_reply":"2022-07-08T06:05:24.684728Z"},"trusted":true},"execution_count":371,"outputs":[]},{"cell_type":"markdown","source":"* 두번째로 간단한 함수를 만들어 apply 메소드에 넣어주는 방법입니다.\n* 훨씬 수월합니다.","metadata":{}},{"cell_type":"code","source":"def category_age(x):\n    if x<10:\n        return 0\n    elif x < 20:\n        return 1\n    elif x < 30:\n        return 2\n    elif x < 40:\n        return 3\n    elif x < 50:\n        return 4\n    elif x < 60:\n        return 5\n    elif x < 70:\n        return 7\ndf_train['Age_cat_2'] = df_train['Age'].apply(category_age)","metadata":{"execution":{"iopub.status.busy":"2022-07-08T06:05:24.687221Z","iopub.execute_input":"2022-07-08T06:05:24.687827Z","iopub.status.idle":"2022-07-08T06:05:24.695635Z","shell.execute_reply.started":"2022-07-08T06:05:24.687783Z","shell.execute_reply":"2022-07-08T06:05:24.694787Z"},"trusted":true},"execution_count":372,"outputs":[]},{"cell_type":"markdown","source":"* 두가지 방법이 잘 적용됬다면, 둘다 같은 결과를 내야합니다.\n* 이를 확인하기 위해 Series rks boolean 비교후 all() 메소드를 사용합시다. all() 메소드는 모든 값이 True면 True, 하나라도 False가 있으면 False를 줍니다.","metadata":{}},{"cell_type":"code","source":"print('1번방법, 2번방법 둘다 같은 결과를 내면 True wnjdigka ->', (df_train['Age_cat']==df_train['Age_cat_2']).all())","metadata":{"execution":{"iopub.status.busy":"2022-07-08T06:05:24.696782Z","iopub.execute_input":"2022-07-08T06:05:24.697470Z","iopub.status.idle":"2022-07-08T06:05:24.712181Z","shell.execute_reply.started":"2022-07-08T06:05:24.697436Z","shell.execute_reply":"2022-07-08T06:05:24.711030Z"},"trusted":true},"execution_count":373,"outputs":[]},{"cell_type":"markdown","source":"###### 1번방법, 2번 방법 둘다 같은 결과를 내면 True 줘야함 -> True","metadata":{}},{"cell_type":"markdown","source":"* 보시다시피 True 입니다. 둘 줄 편한 걸 선택하시면 되겠습니다.\n* 이제 중복되는 Sge_cat 컬럼과 원래 컬럼 Age를 제거하겠습니다.","metadata":{}},{"cell_type":"code","source":"df_train.drop(['Age', 'Age_cat_2'],axis=1, inplace=True)\ndf_test.drop(['Age'], axis=1, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2022-07-08T06:05:24.713919Z","iopub.execute_input":"2022-07-08T06:05:24.714363Z","iopub.status.idle":"2022-07-08T06:05:24.723893Z","shell.execute_reply.started":"2022-07-08T06:05:24.714333Z","shell.execute_reply":"2022-07-08T06:05:24.722852Z"},"trusted":true},"execution_count":374,"outputs":[]},{"cell_type":"markdown","source":"# 3.3 Change Initial, Embarked and Sex (string to numerical)\n* 현재 Initial은 Mr, Mrs, Miss, Master, Other 총 5개로 이루어져 있스빈다. 이런 카테고리로 표현되어져 있는 데이터를 모델에 인풋으로 넣어줄 때 우리가 해야할 것은 먼저 컴퓨터가 인식할 수 있도록 수치화 시켜야 합니다.\n* map method를 가지고 간단히 할 수 있습니다.\n* 사전 순서대로 정리하여 mapping 하겠습니다","metadata":{}},{"cell_type":"code","source":"df_train['Initial'] = df_train['Initial'].map({'Master': 0, 'Miss': 1, 'Mr': 2, 'Mrs':3, 'Other': 4})\ndf_test['Initial'] = df_test['Initial'].map({'Master':0, 'Miss': 1, 'Mr':2, 'Mrs':3, 'Other':4})","metadata":{"execution":{"iopub.status.busy":"2022-07-08T06:05:24.724952Z","iopub.execute_input":"2022-07-08T06:05:24.725651Z","iopub.status.idle":"2022-07-08T06:05:24.735968Z","shell.execute_reply.started":"2022-07-08T06:05:24.725617Z","shell.execute_reply":"2022-07-08T06:05:24.735062Z"},"trusted":true},"execution_count":375,"outputs":[]},{"cell_type":"markdown","source":"* Embarked 도 C,Q,S로 이루어져 있습니다. map을 이용해 바꿔봅시다.\n* 그러기 앞서서, 특정 column에 어떤 값들이 있는 지 확인해보는 방법을 잠깐 살펴보겠습니다. 간단히 unique() 메소드를 쓰거나, value_counts()를 써서 count 까지 보는 방법이 있습니다.","metadata":{}},{"cell_type":"code","source":"df_train['Embarked'].unique()","metadata":{"execution":{"iopub.status.busy":"2022-07-08T06:05:24.737522Z","iopub.execute_input":"2022-07-08T06:05:24.738246Z","iopub.status.idle":"2022-07-08T06:05:24.744860Z","shell.execute_reply.started":"2022-07-08T06:05:24.738215Z","shell.execute_reply":"2022-07-08T06:05:24.743804Z"},"trusted":true},"execution_count":376,"outputs":[]},{"cell_type":"code","source":"df_train['Embarked'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2022-07-08T06:05:24.746282Z","iopub.execute_input":"2022-07-08T06:05:24.746820Z","iopub.status.idle":"2022-07-08T06:05:24.756995Z","shell.execute_reply.started":"2022-07-08T06:05:24.746788Z","shell.execute_reply":"2022-07-08T06:05:24.756235Z"},"trusted":true},"execution_count":377,"outputs":[]},{"cell_type":"markdown","source":"* 위 두 방법을 사용해 Embarked가 S,C,Q 세가지로 이루어진 것을 볼 수 있스빈다. 이제 map을 사용해봅시다","metadata":{}},{"cell_type":"code","source":"df_train['Embarked'] = df_train['Embarked'].map({'C':0, 'Q':1,'S':2})\ndf_test['Embarked'] = df_test['Embarked'].map({'C':0,  'Q':1, 'S':2})","metadata":{"execution":{"iopub.status.busy":"2022-07-08T06:05:24.758378Z","iopub.execute_input":"2022-07-08T06:05:24.758884Z","iopub.status.idle":"2022-07-08T06:05:24.766796Z","shell.execute_reply.started":"2022-07-08T06:05:24.758853Z","shell.execute_reply":"2022-07-08T06:05:24.766004Z"},"trusted":true},"execution_count":378,"outputs":[]},{"cell_type":"markdown","source":"* 한번 Null이 사라졌는지 확인해봅시다. Embarked Column만 가져온 것은 하나의 Pandas의 Series객체므로, isnull()메소드를 사용해 Series의 값들이 null인지 아닌지에 대해 boolean 값을 얻을 수 있습니다. 그리고 이것에 any()를 사용하여, True가 단하나라도 있을시 ( Null이 한개라도 있을 시) Ture를 반환해주게 됩니다. 우리는 Null을 S로 다 바꿔주었으므로 False를 얻게 됩니다","metadata":{}},{"cell_type":"code","source":"df_train['Embarked'].isnull().any()","metadata":{"execution":{"iopub.status.busy":"2022-07-08T06:05:24.768018Z","iopub.execute_input":"2022-07-08T06:05:24.768525Z","iopub.status.idle":"2022-07-08T06:05:24.778428Z","shell.execute_reply.started":"2022-07-08T06:05:24.768495Z","shell.execute_reply":"2022-07-08T06:05:24.777556Z"},"trusted":true},"execution_count":379,"outputs":[]},{"cell_type":"markdown","source":"*Sex도 Female, male 로 이어져 있습니다. map을 이용해 바꿔봅시다.","metadata":{}},{"cell_type":"code","source":"df_train['Sex'] = df_train['Sex'].map({'female': 0, 'male': 1})\ndf_test['Sex'] = df_test['Sex'].map({'female': 0,'male':1})","metadata":{"execution":{"iopub.status.busy":"2022-07-08T06:05:24.779714Z","iopub.execute_input":"2022-07-08T06:05:24.780355Z","iopub.status.idle":"2022-07-08T06:05:24.790011Z","shell.execute_reply.started":"2022-07-08T06:05:24.780287Z","shell.execute_reply":"2022-07-08T06:05:24.789138Z"},"trusted":true},"execution_count":380,"outputs":[]},{"cell_type":"markdown","source":"* 여지껏 고생하셨습니다. 이제 각 Freature 간의 상관관계를 한번 보려고 합니다. 두 변수간의 Pearson correlation을 구하면 (-1, 1) 사이의 값을 얻을 수 있습니다. -1로 갈수록 음의 상관관계, 1로 갈수록 양의 상관관계를 의미하며, 0은 상관관계가 없다는 것을 의미합니다. 구하는 수식은 아래와 같습니다.","metadata":{}},{"cell_type":"markdown","source":"$$r_{xy} = \\frac{Cov(x,y)}{S_{x}S_{y}} = \\frac{\\frac{1}{n-1}\\sum_{i=1}^n(x_{i}-\\bar x)(y_{i}-\\bar y)}{S_{x}S_{y}}$$\n","metadata":{}},{"cell_type":"markdown","source":"* 우리는 여러 feature를 가지고 있으니 이를 하나의 maxtrix형태로 보면 편할 텐데, 이를 heatmap plot 이라고 하며, dataframe의 corr()메소드와 seaborn을 가지고 편하게 그릴 수 있습니다.","metadata":{}},{"cell_type":"code","source":"heatmap_data = df_train[['Survived', 'Pclass', 'Sex', 'Fare', 'Embarked', 'FamilySize', 'Initial', 'Age_cat']] \n\ncolormap = plt.cm.RdBu #plt.cm.RdBu는 나중에 정의된 것 처럼 컬러맵을 나타냄\nplt.figure(figsize=(14, 12))\nplt.title('Pearson Correlation of Features', y=1.05, size=15)\nsns.heatmap(heatmap_data.astype(float).corr(), linewidths=0.1, vmax=1.0,\n           square=True, cmap=colormap, linecolor='white', annot=True, annot_kws={\"size\": 16})\n\ndel heatmap_data","metadata":{"execution":{"iopub.status.busy":"2022-07-08T06:05:24.791241Z","iopub.execute_input":"2022-07-08T06:05:24.792284Z","iopub.status.idle":"2022-07-08T06:05:25.347629Z","shell.execute_reply.started":"2022-07-08T06:05:24.792247Z","shell.execute_reply":"2022-07-08T06:05:25.346469Z"},"trusted":true},"execution_count":381,"outputs":[]},{"cell_type":"markdown","source":"* 우리가 EDA에서 살펴봣듯이, Sex와 Pclass가 Survived에 상관관계가 어느 정도 있음을 볼 수 있습니다.\n* 생각보다 fare 와 Embarked 도 상관관계가 있음을 볼 수 있습니다.\n* 또한 우리가 여기서 얻을 수 있는 정보는 서로 강한 상관관계를 가지는 feature들이 없다는 것입니다.\n* 이것은 우리가 모델을 학습시킬 떄, 불필요한(redundant, superfluous) feature가 없다는 것을 의미합니다. 1 또는 -1의 상관관계를 가진 feature A,B가 있다면, 우리가 얻을 수 있는 정보는 사실 하나일 거니까요.\n* 이제 실제로 모델을 학습시키기 앞서서 data preprocessing(전처리)을 진행해보겠습니다. ","metadata":{}},{"cell_type":"markdown","source":"# 3.4 One-hot encoding on Initial and Embarked","metadata":{}},{"cell_type":"markdown","source":"* 수치화시킨 카테고리 데이터를 그대로 넣어도 되지만, 모델의 성능을 높이기 위해 one-hot encoding을 해줄 수 있습니다\n* 수치화는 간단히 Master ==0, Miss ==1, Mr ==2, Mrs ==3, Other ==4로 매핑해주는 것을 말합니다.\n* One-hot encoding은 위 카테고리를 아래와 같이 (0,1)로 이루어진 5차원의 벡터로 나타내는 것을 말합니다.\n* 위와 같은 작업을 직접 코딩할 수도 있지만, pandas의 get_dummiesfmf 사용하여 쉽게 해결할 수 있습니다.\n* 총 5개의 카테고리니, one-hot encoding을 하고 나면 새로운 5개의 column이 생겨납니다. \n* Initial을 prefix로 두어서 구분이 쉽게 만들어 줍니다.","metadata":{}},{"cell_type":"code","source":"df_train = pd.get_dummies(df_train, columns = ['Initial'], prefix='Initial')\ndf_test = pd.get_dummies(df_test, columns=['Initial'], prefix='Initial')","metadata":{"execution":{"iopub.status.busy":"2022-07-08T06:05:25.349228Z","iopub.execute_input":"2022-07-08T06:05:25.350175Z","iopub.status.idle":"2022-07-08T06:05:25.364904Z","shell.execute_reply.started":"2022-07-08T06:05:25.350132Z","shell.execute_reply":"2022-07-08T06:05:25.363689Z"},"trusted":true},"execution_count":382,"outputs":[]},{"cell_type":"code","source":"df_train.head()","metadata":{"execution":{"iopub.status.busy":"2022-07-08T06:05:25.366462Z","iopub.execute_input":"2022-07-08T06:05:25.366806Z","iopub.status.idle":"2022-07-08T06:05:25.385786Z","shell.execute_reply.started":"2022-07-08T06:05:25.366775Z","shell.execute_reply":"2022-07-08T06:05:25.384776Z"},"trusted":true},"execution_count":383,"outputs":[]},{"cell_type":"markdown","source":"* 보시다시피 오른쪽에 우리가 만들려고 했던 One-hot-encoded columns가 생성된 것이 보입니다.\n* Embarked 에도 적용하겠습니다. Initial 떄와 마찬가지로 one-hot encoding을 사용해 표현하겠습니다.","metadata":{}},{"cell_type":"code","source":"df_train = pd.get_dummies(df_train, columns=['Embarked'], prefix='Embarked')\ndf_test = pd.get_dummies(df_test, columns=['Embarked'], prefix='Embarked')","metadata":{"execution":{"iopub.status.busy":"2022-07-08T06:05:25.387054Z","iopub.execute_input":"2022-07-08T06:05:25.387777Z","iopub.status.idle":"2022-07-08T06:05:25.402643Z","shell.execute_reply.started":"2022-07-08T06:05:25.387714Z","shell.execute_reply":"2022-07-08T06:05:25.401553Z"},"trusted":true},"execution_count":384,"outputs":[]},{"cell_type":"markdown","source":"* 아주 쉽게 one-hot encoding을 적용했습니다.\n* sklearn로 Labelencodere + OneHotencoder 이용해도 one-hot encoding이 가능합니다\n* 다른 튜토리얼을 한번 써보겠습니다. 여기서는 get_dummies 로 충분히 가능하기 때문에 get_dummies 만으로 끝내겠습니다.\n* 가끔 category가 100개가 넘어가는 경우가 있습니다. 이때 one-hot encoding을 사용하면 column이 100개가 생겨, 학습 시 버거울 경우가 있습니다. 이런 경우는 다른방법을 사용하기도 하는데, 이는 다음에 한번 다뤄보겠습니다.","metadata":{}},{"cell_type":"markdown","source":"# 3.5 Drop columns","metadata":{}},{"cell_type":"markdown","source":"* 필요한 columns만 남기고 다 지웁시다","metadata":{}},{"cell_type":"code","source":"df_train.drop(['PassengerId','Name', 'SibSp', 'Parch', 'Ticket', 'Cabin'], axis=1, inplace=True)\ndf_test.drop(['PassengerId', 'Name', 'SibSp', 'Parch', 'Ticket', 'Cabin'], axis=1, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2022-07-08T06:05:25.404591Z","iopub.execute_input":"2022-07-08T06:05:25.405276Z","iopub.status.idle":"2022-07-08T06:05:25.415401Z","shell.execute_reply.started":"2022-07-08T06:05:25.405232Z","shell.execute_reply":"2022-07-08T06:05:25.414249Z"},"trusted":true},"execution_count":385,"outputs":[]},{"cell_type":"code","source":"df_train.head()","metadata":{"execution":{"iopub.status.busy":"2022-07-08T06:05:25.417455Z","iopub.execute_input":"2022-07-08T06:05:25.418353Z","iopub.status.idle":"2022-07-08T06:05:25.437566Z","shell.execute_reply.started":"2022-07-08T06:05:25.418308Z","shell.execute_reply":"2022-07-08T06:05:25.436419Z"},"trusted":true},"execution_count":386,"outputs":[]},{"cell_type":"code","source":"df_test.head()","metadata":{"execution":{"iopub.status.busy":"2022-07-08T06:05:25.439384Z","iopub.execute_input":"2022-07-08T06:05:25.439929Z","iopub.status.idle":"2022-07-08T06:05:25.454031Z","shell.execute_reply.started":"2022-07-08T06:05:25.439895Z","shell.execute_reply":"2022-07-08T06:05:25.452974Z"},"trusted":true},"execution_count":387,"outputs":[]},{"cell_type":"markdown","source":"* 보시다시피, train의 Survived feature(tager class)을 뺴면 train, test 둘다 같은 columns를 가진 걸 확인할 수 있습니다.","metadata":{}},{"cell_type":"markdown","source":"# 4. Building Machin learning model and prediciton using the trained model","metadata":{}},{"cell_type":"markdown","source":"* 이제 준비가 다 되었으니 sklearn을 사용해 본격적을 머신러닝 모델을 만들어 봅시다.","metadata":{}},{"cell_type":"code","source":"#importin all the required ML packages\nfrom sklearn.ensemble import RandomForestClassifier # 유명한 randomforestclassfier 입니다.\nfrom sklearn import metrics # 모델의 평가를 위해서 씁니다\nfrom sklearn.model_selection import train_test_split # traning set을 쉽게 나눠주는 함수입니다.","metadata":{"execution":{"iopub.status.busy":"2022-07-08T06:05:25.455526Z","iopub.execute_input":"2022-07-08T06:05:25.456149Z","iopub.status.idle":"2022-07-08T06:05:25.464659Z","shell.execute_reply.started":"2022-07-08T06:05:25.456105Z","shell.execute_reply":"2022-07-08T06:05:25.463711Z"},"trusted":true},"execution_count":388,"outputs":[]},{"cell_type":"markdown","source":"* Sklearn은 머신러닝의 처음부터 끝까지가 다 있습니다. feature engineering, preprocessing, 지도 학습 알고지름, 비지도 학습 알고리즘, 모델 명가, 파이프라인 등 머신러닝에 관련된 모든 작업들이 손쉬운 인터페이스로 구현되어 있습니다. 데이터 분석 + 머신러닝을 하고 싶다면, 이 라이브러리는 반드시 숙지해야합니다.\n* 파이썬 라이브러리를 활용한 머신러닝 책을 사서 공부하시길 매우 추천\n* 지금 타이타닉 문제는 target class(survived)가 있으며, target class는 0,1 로 이루어져 있으므로 (binary) binary classfication문제입니다.\n* 우리가 지금 가지고 있는 train set 의 survived를 제외한 input을 자긴고 모델을 최적화시켜서 각 샘플(탑승객)의 생존유무를 판단하는 모델을 만들어 냅니다.\n* 그후 모델이 학습하지 않았던 test set 을 input으로 주어서 test set 의 각 샘플(탑승객)의 생존 유무를 예측해봅니다.","metadata":{}},{"cell_type":"markdown","source":"# 4.1 Preparation - Split dataset into train, valid, test set\n*    가장먼저, 학습에 쓰일 데이터와 , target laber(Survived)를 분리합니다. drop을 사용해 간단히 할 수 있습니다.","metadata":{}},{"cell_type":"code","source":"X_train = df_train.drop('Survived', axis=1).values\ntarget_label = df_train['Survived'].values\nX_test = df_test.values","metadata":{"execution":{"iopub.status.busy":"2022-07-08T06:05:25.473520Z","iopub.execute_input":"2022-07-08T06:05:25.474081Z","iopub.status.idle":"2022-07-08T06:05:25.481440Z","shell.execute_reply.started":"2022-07-08T06:05:25.474039Z","shell.execute_reply":"2022-07-08T06:05:25.480434Z"},"trusted":true},"execution_count":389,"outputs":[]},{"cell_type":"markdown","source":"* 보통 train, test 만 언급되지만, 실제 좋은 모델을 만들기 위해서 우리는 valid set을 따로 만들어 모델평가를 해봅니다\n* 마치 축구대표팀이 팀훈련(train)을 하고 바로 월드컵(test)로 나가는 것이 아니라, 팀훈련(train)을 한 다음 평가전(valid)를 거쳐 팀 훈련 정도(학습정도)를 확인하고 월드컵(test)에 나가는 것과 비슷합니다.\n* trian_test_split을 사용하여 쉽게 train 셋을 분리할 수 있습니다.","metadata":{}},{"cell_type":"code","source":"X_tr, X_vld, y_tr, y_vld = train_test_split(X_train, target_label, test_size=0.3, random_state=2018)","metadata":{"execution":{"iopub.status.busy":"2022-07-08T06:05:25.482845Z","iopub.execute_input":"2022-07-08T06:05:25.483258Z","iopub.status.idle":"2022-07-08T06:05:25.491863Z","shell.execute_reply.started":"2022-07-08T06:05:25.483227Z","shell.execute_reply":"2022-07-08T06:05:25.490754Z"},"trusted":true},"execution_count":390,"outputs":[]},{"cell_type":"markdown","source":"* sklearn 에서는 여러 머신러닝 알고리즘을 지원해줍니다. 열거하기엔 너무 많으므로, 직접 documentation에 들어가 보시길 추천합니다. http://scikit-learn.org/stable/supervised_learning.html#supervised-learning 여기에 들어가시면 지원되는 알고리즘 수에 놀라실 겁니다.\n* 본 튜토리얼에서는 랜덤포레스트 모델을 사용하도록 하겠습니다. \n* 랜덤포레스트는 결정트리기반 모델이며, 여러 결정 트리들을 앙상블한 모델입니다. 더 구체적인 모델 설명은 여러 블로그들 참고하시면 될 것이고, 저도 한번 추후 다뤄보겠습니다.\n* 각 머신러닝 알고리즘에는 여러 파라미터들이 있습니다. 랜덤포레스트분류기도 n_estimators, max_features, max_depth, min_samples_split, min_samples_leaf등 여러 파라미터들이 존재합니다. 이것들이 어떻게 세팅되냐에 따라 같은 데이터셋이라 하더라도 모델의 성능이 달라집니다.\n* 파라미터 튜닝은 시간, 경험, 알고리즘에 대한 이해 등이 필요합니다. 결국 ㅁ낳이 써봐야 모델도 잘 세울 수 있는 것이죠. 그래서 캐글을 추천합니다. 여러 데이터셋을 가지고 모델을 이리저리 써봐야 튜닝하는 감이 생길테니까요!\n* 일단 지금은 튜토리얼이니 파라미터 튜닝은 잠시 제쳐두기로 하고, 기본 default 세팅으로 진행하겠습니다.\n* 모델 객체를 만들고, fit 메소드로 학습시킵니다.\n* 그런 후 valid set input을 넣어주어 예측값(x_vldsample(탑승객)의 생존여부)를 얻습니다.","metadata":{}},{"cell_type":"markdown","source":"# 4.2 Model generation and prediciton","metadata":{}},{"cell_type":"code","source":"model = RandomForestClassifier()\nmodel.fit(X_tr, y_tr)\nprediction = model.predict(X_vld)","metadata":{"execution":{"iopub.status.busy":"2022-07-08T06:05:25.493245Z","iopub.execute_input":"2022-07-08T06:05:25.493900Z","iopub.status.idle":"2022-07-08T06:05:25.672858Z","shell.execute_reply.started":"2022-07-08T06:05:25.493864Z","shell.execute_reply":"2022-07-08T06:05:25.671926Z"},"trusted":true},"execution_count":391,"outputs":[]},{"cell_type":"markdown","source":"* 단 세줄만으로 여러분은 모델을 세우고, 예측까지 해봤습니다.\n* 자 이제 모델의 성능을 한번 보겠습니다.","metadata":{}},{"cell_type":"code","source":"print('총 {}명 중 {:.2f}%정확도로 생존을 맞춤'.format(y_vld.shape[0], 100*metrics.accuracy_score(prediction, y_vld)))","metadata":{"execution":{"iopub.status.busy":"2022-07-08T06:05:25.674012Z","iopub.execute_input":"2022-07-08T06:05:25.674706Z","iopub.status.idle":"2022-07-08T06:05:25.681439Z","shell.execute_reply.started":"2022-07-08T06:05:25.674664Z","shell.execute_reply":"2022-07-08T06:05:25.680382Z"},"trusted":true},"execution_count":392,"outputs":[]},{"cell_type":"markdown","source":"# 4.3 Feature importance\n* 학습된 모델은 feature importance를 가지게 되는데, 우리는 이것을 확인하여 지금 만든 모델이 어떤 feature에 영향을 많이 받았는지 확인할 수 있습니다.\n* 쉽게 말게, 10 = 4x1 + 2x2 + 1*x3을 생각하면, 우리는 x1이 결과값(10)에 큰 영향을 준다고 생각 할 수 있습니다. feature importance는 4,2,1을 이야기하며, x1이 가장 큰 값(4)를 가지므로, 이모델에 가장 큰 영향을 미친다고 말할 수 있습니다.\n* 학습된 모델은 기본적으로 featureimportances 를 가지고 있어서 쉽게 그 수치를 얻을 수 있습니다.\n* pandas series 를 이용하면 쉽게 soritng 을 하여 그래프를 그릴 수 있습니다.","metadata":{}},{"cell_type":"code","source":"from pandas import Series\n\nfeature_importance = model.feature_importances_\nSeries_feat_imp = Series(feature_importance, index=df_test.columns)","metadata":{"execution":{"iopub.status.busy":"2022-07-08T06:05:25.682736Z","iopub.execute_input":"2022-07-08T06:05:25.683044Z","iopub.status.idle":"2022-07-08T06:05:25.702480Z","shell.execute_reply.started":"2022-07-08T06:05:25.683018Z","shell.execute_reply":"2022-07-08T06:05:25.701429Z"},"trusted":true},"execution_count":393,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(8, 8))\nSeries_feat_imp.sort_values(ascending=True).plot.barh()\nplt.xlabel('Feature importance')\nplt.ylabel('Feature')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-07-08T06:05:25.703791Z","iopub.execute_input":"2022-07-08T06:05:25.704674Z","iopub.status.idle":"2022-07-08T06:05:25.971737Z","shell.execute_reply.started":"2022-07-08T06:05:25.704638Z","shell.execute_reply":"2022-07-08T06:05:25.970577Z"},"trusted":true},"execution_count":394,"outputs":[]},{"cell_type":"markdown","source":"* 우리가 얻은 모델에서는 Fare 가 가장 큰 영향력을 가지며, 그 뒤로 Initial_2, Age_cat,Pclass가 차례로 중요도를 가집니다\n* 사실 feature importance 는 지금 모델에서의 importance를 나타냅니다. 만약 다른 모델을 사용하게 된다면 feature importance가 다르게 나올 수 있습니다.\n* 이 feature importance를 보고 Fare가 중요한 feature 일 수 있다고 판단을 내릴 수는 있지만, 이것은 결국 모델에 귀속되는 하나의 결론이므로 통계적으로 좀 더 살펴보긴 해야합니다.\n* feature importance를 가지고 좀 더 정확도가 높은 모델을 얻기 위해 feature selection을 할 수 도 있고, 좀 더 빠른 모델을 얻기위해 feature 제거를 할 수 있습니다.","metadata":{}},{"cell_type":"markdown","source":"# 4.4 Prediction on Test set\n* 이제 모델이 학습하지 않았던(보지 않았던) 테스트셋을 모델에 주어서, 생존여부를 예측해보겠습니다.\n* 이 결과는 실제로 submission(제출용) 이므로 결과는 leaderboard에서 확인할 수 있습니다.\n* 캐글에서 준 파일, gender_submission.csv 파일을 읽어서 제출 준비를 하겠습니다.","metadata":{}},{"cell_type":"code","source":"submission = pd.read_csv('../input/titanic/gender_submission.csv')\nsubmission.head()","metadata":{"execution":{"iopub.status.busy":"2022-07-08T06:05:25.972937Z","iopub.execute_input":"2022-07-08T06:05:25.973238Z","iopub.status.idle":"2022-07-08T06:05:25.986403Z","shell.execute_reply.started":"2022-07-08T06:05:25.973210Z","shell.execute_reply":"2022-07-08T06:05:25.985257Z"},"trusted":true},"execution_count":395,"outputs":[]},{"cell_type":"markdown","source":"이제 testset에 대해여 예측을 하고, 그 결과를 csv 파일로 저장해보겠습니다.","metadata":{}},{"cell_type":"code","source":"prediction = model.predict(X_test)\nsubmission['Survived'] = prediction","metadata":{"execution":{"iopub.status.busy":"2022-07-08T06:05:25.988644Z","iopub.execute_input":"2022-07-08T06:05:25.988972Z","iopub.status.idle":"2022-07-08T06:05:26.012772Z","shell.execute_reply.started":"2022-07-08T06:05:25.988944Z","shell.execute_reply":"2022-07-08T06:05:26.011929Z"},"trusted":true},"execution_count":396,"outputs":[]},{"cell_type":"code","source":"submission.to_csv('./my_first_submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2022-07-08T06:05:26.013912Z","iopub.execute_input":"2022-07-08T06:05:26.014349Z","iopub.status.idle":"2022-07-08T06:05:26.019796Z","shell.execute_reply.started":"2022-07-08T06:05:26.014320Z","shell.execute_reply":"2022-07-08T06:05:26.018924Z"},"trusted":true},"execution_count":397,"outputs":[]}]}